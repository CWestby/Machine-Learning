---
title: "Practical Machine"
author: "Charles Westby"
date: "December 17, 2015"
output: html_document
---

#Synopsis
In this report we will be using data from the accelerometers on the belt, forearm, arm, and dumbell of 6 participants. These participants were asked to perform barbell lifts both correctly and incorrectly in 5 different ways. This data was used to create training and test sets. These training and test sets will be used to predict whether the exercise was done correctly or incorrectly. Whether the exercise was done correctly or incorrectly is represented by the variable "classe" in the training set. We will build multiple prediction models and use cross-validation. We will use the best model and try to predict 20 different test cases.

# Processing Data

### Loading Libraries and Data ###
```{r warning=FALSE, error=FALSE, message=FALSE}
setwd("~/GitHub/Machine-Learning")
library(caret); library(caretEnsemble); library(AppliedPredictiveModeling); library(ggplot2); library(dplyr); library(rpart); library(rattle); library(rpart.plot); library(knitr); library(ElemStatLearn); library(randomForest); library(lattice)

if (!file.exists("pml-training.csv")) {
    fileURL   <-  'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
    download.file(fileURL, destfile="pml-training.csv", method = "curl")
}
training_data <-  read.csv("pml-training.csv", na.strings = c("NA","#DIV/0!", ""), header=TRUE)

if (!file.exists("pml-testing.csv")) {
    fileURL   <-  'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
    download.file(fileURL, destfile="pml-testing.csv", method = "curl")
}
testing_data  <-  read.csv("pml-testing.csv", na.strings = c("NA","#DIV/0!", ""), header=TRUE)

inTrain       <- createDataPartition(y=training_data$classe, p=0.6, list=FALSE)
training      <- training_data[inTrain, ]
testing       <- training_data[-inTrain, ]
dim(training); dim(testing)


```


## Cleaning Data
```{r}
nzv           <- nearZeroVar(training, saveMetrics=TRUE)
training      <- training[,nzv$nzv==FALSE]

nzv           <- nearZeroVar(testing,saveMetrics=TRUE)
testing       <- testing[,nzv$nzv==FALSE]

training      <- training[c(-1)]

trainingV3    <- training
for(i in 1:length(training)) {
    if( sum( is.na( training[, i] ) ) /nrow(training) >= .7) {
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(training[i]), names(trainingV3)[j]) ) == 1)  {
                trainingV3 <- trainingV3[ , -j]
            }   
        } 
    }
}


training        <- trainingV3
rm(trainingV3)

clean1          <- colnames(training)
clean2          <- colnames(training[, -58])  
testing         <- testing[clean1]         
testing_data    <- testing_data[clean2]            

dim(testing)
dim(testing_data)
```
##  Predictive Models

### Classification Tree Model
```{r}
set.seed(828)
modFitCT          <- rpart(classe ~ ., data=training, method="class")
fancyRpartPlot(modFitCT)

predictionsCT     <- predict(modFitCT, testing, type = "class")
confusionMatrix(predictionsCT, testing$classe)

```

### Random Forest Model
```{r}
set.seed(828)
modFitRF          <- randomForest(classe ~ ., data=training)
predictionsRF     <- predict(modFitRF, testing, type= "class")
confusionMatrix(predictionsRF, testing$classe)

```

```{r}
predictionRF2     <- predict(modFitRF, testing, type = "class")

pml_write_files = function(x){
    n = length(x)
    for(i in 1:n){
        filename = paste0("problem_id_",i,".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
}
```

# Conclusion

- Accuracy from the Classification Tree model was 86.9%. Therefore, the out of sample error rate for this model should be about 13.1%.
- Accuracy from the Random Forest model was 99.9%. Therefore, the out of sample error rate for this model should be about 0.1%
- In the end, we use the Random Forest model because it is the better predictor.

